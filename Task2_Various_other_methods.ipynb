{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\smadh\\anaconda3\\Lib\\site-packages\\pandas\\core\\arrays\\masked.py:60: UserWarning: Pandas requires version '1.3.6' or newer of 'bottleneck' (version '1.3.5' currently installed).\n",
      "  from pandas.core import (\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "data = pd.read_csv('fraudtrain.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\smadh\\anaconda3\\Lib\\site-packages\\sklearn\\preprocessing\\_encoders.py:868: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
      "  warnings.warn(\n",
      "c:\\Users\\smadh\\anaconda3\\Lib\\site-packages\\sklearn\\preprocessing\\_encoders.py:868: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
      "  warnings.warn(\n",
      "c:\\Users\\smadh\\anaconda3\\Lib\\site-packages\\sklearn\\preprocessing\\_encoders.py:868: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
      "  warnings.warn(\n",
      "c:\\Users\\smadh\\anaconda3\\Lib\\site-packages\\sklearn\\preprocessing\\_encoders.py:868: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
      "  warnings.warn(\n",
      "c:\\Users\\smadh\\anaconda3\\Lib\\site-packages\\sklearn\\preprocessing\\_encoders.py:868: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
      "  warnings.warn(\n",
      "c:\\Users\\smadh\\anaconda3\\Lib\\site-packages\\sklearn\\preprocessing\\_encoders.py:868: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
      "  warnings.warn(\n",
      "c:\\Users\\smadh\\anaconda3\\Lib\\site-packages\\sklearn\\preprocessing\\_encoders.py:868: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
      "  warnings.warn(\n",
      "c:\\Users\\smadh\\anaconda3\\Lib\\site-packages\\sklearn\\preprocessing\\_encoders.py:868: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
      "  warnings.warn(\n",
      "c:\\Users\\smadh\\anaconda3\\Lib\\site-packages\\sklearn\\preprocessing\\_encoders.py:868: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
      "  warnings.warn(\n",
      "c:\\Users\\smadh\\anaconda3\\Lib\\site-packages\\sklearn\\preprocessing\\_encoders.py:868: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
      "  warnings.warn(\n",
      "c:\\Users\\smadh\\anaconda3\\Lib\\site-packages\\sklearn\\preprocessing\\_encoders.py:868: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
      "  warnings.warn(\n",
      "c:\\Users\\smadh\\anaconda3\\Lib\\site-packages\\sklearn\\preprocessing\\_encoders.py:868: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final sparse matrix shape: (1296675, 709)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\smadh\\anaconda3\\Lib\\site-packages\\sklearn\\preprocessing\\_encoders.py:868: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from scipy.sparse import csr_matrix, vstack\n",
    "\n",
    "# Function to process data in chunks and convert to sparse matrix\n",
    "def process_data_chunks(file_path, chunk_size):\n",
    "    chunks = pd.read_csv(file_path, chunksize=chunk_size)\n",
    "    sparse_chunks = []\n",
    "    \n",
    "    # Example: Initialize StandardScaler and OneHotEncoder\n",
    "    scaler = StandardScaler()\n",
    "    encoder = OneHotEncoder(handle_unknown='ignore', sparse=True)\n",
    "    \n",
    "    for chunk in chunks:\n",
    "        # Example: Perform feature engineering on each chunk\n",
    "        chunk['trans_hour'] = pd.to_datetime(chunk['trans_date_trans_time']).dt.hour\n",
    "        chunk['trans_day_of_week'] = pd.to_datetime(chunk['trans_date_trans_time']).dt.dayofweek\n",
    "        \n",
    "        # Example: Scaling numerical features\n",
    "        numerical_features = ['amt', 'lat', 'long', 'city_pop']\n",
    "        chunk[numerical_features] = scaler.fit_transform(chunk[numerical_features])\n",
    "        \n",
    "        # Example: Apply OneHotEncoder to categorical features\n",
    "        categorical_features = ['merchant', 'category', 'gender']\n",
    "        encoded_features = encoder.fit_transform(chunk[categorical_features])\n",
    "        \n",
    "        # Convert to sparse matrix\n",
    "        sparse_data = csr_matrix(encoded_features)\n",
    "        sparse_chunks.append(sparse_data)\n",
    "    \n",
    "    # Concatenate all sparse chunks into a single sparse matrix\n",
    "    final_sparse_matrix = vstack(sparse_chunks)\n",
    "    \n",
    "    return final_sparse_matrix\n",
    "\n",
    "# Example usage\n",
    "file_path = 'fraudtrain.csv'  # Replace with your actual dataset file path\n",
    "chunk_size = 100000  # Adjust based on your system's memory capacity\n",
    "\n",
    "final_sparse_matrix = process_data_chunks(file_path, chunk_size)\n",
    "print(\"Final sparse matrix shape:\", final_sparse_matrix.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Isolation Forest - Anamoly Method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Contamination=0.01, n_estimators=100, ROC AUC Score: 0.5010884423959653\n",
      "Contamination=0.01, n_estimators=200, ROC AUC Score: 0.501038765046744\n",
      "Contamination=0.01, n_estimators=300, ROC AUC Score: 0.5016353461835649\n",
      "Contamination=0.02, n_estimators=100, ROC AUC Score: 0.49921203315923185\n",
      "Contamination=0.02, n_estimators=200, ROC AUC Score: 0.5010771123622916\n",
      "Contamination=0.02, n_estimators=300, ROC AUC Score: 0.5031807347067512\n",
      "Contamination=0.05, n_estimators=100, ROC AUC Score: 0.5009252669447798\n",
      "Contamination=0.05, n_estimators=200, ROC AUC Score: 0.5078048174588674\n",
      "Contamination=0.05, n_estimators=300, ROC AUC Score: 0.5060747481108955\n",
      "Best ROC AUC Score: 0.5078048174588674\n"
     ]
    }
   ],
   "source": [
    "# Example: Train and evaluate a model (Isolation Forest)\n",
    "from sklearn.ensemble import IsolationForest\n",
    "from sklearn.metrics import classification_report, roc_auc_score\n",
    "\n",
    "# Assuming final_sparse_matrix is your processed sparse matrix and is_fraud is your target variable\n",
    "X = final_sparse_matrix\n",
    "y = data['is_fraud']\n",
    "\n",
    "# Train-test split if not already done\n",
    "# Example: Splitting data into training and testing sets\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "from sklearn.ensemble import IsolationForest\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "# Example of hyperparameter tuning\n",
    "best_score = 0\n",
    "best_model = None\n",
    "for contamination in [0.01, 0.02, 0.05]:\n",
    "    for n_estimators in [100, 200, 300]:\n",
    "        iso_forest = IsolationForest(contamination=contamination, n_estimators=n_estimators, random_state=42)\n",
    "        iso_forest.fit(X_train)\n",
    "        y_pred_iso = iso_forest.predict(X_test)\n",
    "        roc_auc = roc_auc_score(y_test, y_pred_iso)\n",
    "        print(f'Contamination={contamination}, n_estimators={n_estimators}, ROC AUC Score: {roc_auc}')\n",
    "        if roc_auc > best_score:\n",
    "            best_score = roc_auc\n",
    "            best_model = iso_forest\n",
    "\n",
    "print(f'Best ROC AUC Score: {best_score}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "OverSampling the Data using Smote"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "# Instantiate SMOTE\n",
    "smote = SMOTE(random_state=42)\n",
    "\n",
    "# Apply SMOTE to the training set\n",
    "X_train_smote, y_train_smote = smote.fit_resample(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Random Forest Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# Instantiate Random Forest Classifier\n",
    "rf_clf = RandomForestClassifier(random_state=42)\n",
    "\n",
    "# Train the model on the SMOTE balanced training data\n",
    "rf_clf.fit(X_train_smote, y_train_smote)\n",
    "\n",
    "# Predict on the test set\n",
    "y_pred_rf = rf_clf.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "print(classification_report(y_test, y_pred_rf))\n",
    "print(f'ROC AUC Score: {roc_auc_score(y_test, y_pred_rf)}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\smadh\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.65      0.79    257815\n",
      "           1       0.01      0.70      0.02      1520\n",
      "\n",
      "    accuracy                           0.65    259335\n",
      "   macro avg       0.50      0.67      0.40    259335\n",
      "weighted avg       0.99      0.65      0.78    259335\n",
      "\n",
      "ROC AUC Score: 0.6745478640334716\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# Instantiate Logistic Regression Classifier\n",
    "logreg_clf = LogisticRegression(random_state=42)\n",
    "\n",
    "# Train the model on the SMOTE balanced training data\n",
    "logreg_clf.fit(X_train_smote, y_train_smote)\n",
    "\n",
    "# Predict on the test set\n",
    "y_pred_logreg = logreg_clf.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "print(classification_report(y_test, y_pred_logreg))\n",
    "print(f'ROC AUC Score: {roc_auc_score(y_test, y_pred_logreg)}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Random UnderSampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original training dataset shape: Counter({0: 1031354, 1: 5986})\n",
      "Resampled training dataset shape: Counter({0: 5986, 1: 5986})\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "from sklearn.model_selection import train_test_split\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from sklearn.metrics import classification_report, roc_auc_score\n",
    "\n",
    "# Assuming X_train, X_test, y_train, y_test are your training and test sets\n",
    "print(\"Original training dataset shape:\", Counter(y_train))\n",
    "\n",
    "# Apply random undersampling\n",
    "rus = RandomUnderSampler(random_state=42)\n",
    "X_train_rus, y_train_rus = rus.fit_resample(X_train, y_train)\n",
    "\n",
    "print(\"Resampled training dataset shape:\", Counter(y_train_rus))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\smadh\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.69      0.81    257815\n",
      "           1       0.01      0.67      0.02      1520\n",
      "\n",
      "    accuracy                           0.69    259335\n",
      "   macro avg       0.50      0.68      0.42    259335\n",
      "weighted avg       0.99      0.69      0.81    259335\n",
      "\n",
      "ROC AUC Score: 0.6788795540866206\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# Instantiate Logistic Regression Classifier\n",
    "logreg_clf = LogisticRegression(random_state=42)\n",
    "\n",
    "# Train the model on the SMOTE balanced training data\n",
    "logreg_clf.fit(X_train_rus, y_train_rus)\n",
    "\n",
    "# Predict on the test set\n",
    "y_pred_logreg = logreg_clf.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "print(classification_report(y_test, y_pred_logreg))\n",
    "print(f'ROC AUC Score: {roc_auc_score(y_test, y_pred_logreg)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cluster Centroids Undersampling:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "from sklearn.model_selection import train_test_split\n",
    "from imblearn.under_sampling import ClusterCentroids\n",
    "from sklearn.metrics import classification_report, roc_auc_score\n",
    "\n",
    "# Assuming X_train, X_test, y_train, y_test are your training and test sets\n",
    "print(\"Original training dataset shape:\", Counter(y_train))\n",
    "\n",
    "# Apply Cluster Centroids undersampling\n",
    "cc = ClusterCentroids(random_state=42)\n",
    "X_train_cc, y_train_cc = cc.fit_resample(X_train, y_train)\n",
    "\n",
    "print(\"Resampled training dataset shape:\", Counter(y_train_cc))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# Instantiate Logistic Regression Classifier\n",
    "logreg_clf = LogisticRegression(random_state=42)\n",
    "\n",
    "# Train the model on the SMOTE balanced training data\n",
    "logreg_clf.fit(X_train_cc, y_train_cc)\n",
    "\n",
    "# Predict on the test set\n",
    "y_pred_logreg = logreg_clf.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "print(classification_report(y_test, y_pred_logreg))\n",
    "print(f'ROC AUC Score: {roc_auc_score(y_test, y_pred_logreg)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Class Weight Adjustment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original training dataset shape: Counter({0: 1031354, 1: 1031354})\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\smadh\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.65      0.79    257815\n",
      "           1       0.01      0.70      0.02      1520\n",
      "\n",
      "    accuracy                           0.65    259335\n",
      "   macro avg       0.50      0.67      0.40    259335\n",
      "weighted avg       0.99      0.65      0.78    259335\n",
      "\n",
      "ROC AUC Score: 0.6745478640334716\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report, roc_auc_score\n",
    "\n",
    "# Assuming X_train, X_test, y_train, y_test are your training and test sets\n",
    "print(\"Original training dataset shape:\", Counter(y_train))\n",
    "\n",
    "# Train logistic regression with class weight adjustment\n",
    "model = LogisticRegression(class_weight='balanced', random_state=42)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Predict on the test set\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "print(classification_report(y_test, y_pred))\n",
    "print(f'ROC AUC Score: {roc_auc_score(y_test, y_pred)}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set shape after SMOTE: (2062708, 709)\n",
      "Testing set shape: (259335, 709)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import classification_report, roc_auc_score\n",
    "\n",
    "# Assuming X_train_smote, X_test, y_train_smote, y_test are your training and test sets post-SMOTE\n",
    "print(\"Training set shape after SMOTE:\", X_train_smote.shape)\n",
    "print(\"Testing set shape:\", X_test.shape)\n",
    "\n",
    "# Train SVM model\n",
    "svm_model = SVC(kernel='rbf', random_state=42)\n",
    "svm_model.fit(X_train_smote, y_train_smote)\n",
    "\n",
    "# Predict on the test set\n",
    "y_pred_svm = svm_model.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "print(\"SVM Model:\")\n",
    "print(classification_report(y_test, y_pred_svm))\n",
    "print(f'ROC AUC Score: {roc_auc_score(y_test, y_pred_svm)}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ensemble Methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from imblearn.ensemble import BalancedRandomForestClassifier\n",
    "from sklearn.metrics import classification_report, roc_auc_score\n",
    "\n",
    "# Initialize Balanced Random Forest classifier\n",
    "brf_model = BalancedRandomForestClassifier(n_estimators=100, random_state=42)\n",
    "\n",
    "# Train the model on the training set (X_train, y_train)\n",
    "brf_model.fit(X_train, y_train)\n",
    "\n",
    "# Predict on the test set\n",
    "y_pred_brf = brf_model.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "print(\"Balanced Random Forest Model:\")\n",
    "print(classification_report(y_test, y_pred_brf))\n",
    "print(f'ROC AUC Score: {roc_auc_score(y_test, y_pred_brf)}')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
